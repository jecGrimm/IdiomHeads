slurmstepd-diamiktit: error: Unable to create TMPDIR [/tmp/user/32202]: Permission denied
slurmstepd-diamiktit: error: Setting TMPDIR to /tmp
/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.
Loaded pretrained model pythia-1.4b into HookedTransformer
Running compute_literal_only on device cuda.

Processing split formal:
Map:   0%|          | 0/2760 [00:00<?, ? examples/s]Map:   0%|          | 1/2760 [00:09<7:19:20,  9.55s/ examples]Map:   0%|          | 2/2760 [00:14<5:06:11,  6.66s/ examples]Map:   0%|          | 3/2760 [00:20<5:01:17,  6.56s/ examples]Map:   0%|          | 4/2760 [02:49<47:58:22, 62.66s/ examples]Map:   0%|          | 5/2760 [03:29<41:42:11, 54.49s/ examples]Map:   0%|          | 6/2760 [03:34<28:44:48, 37.58s/ examples]Map:   0%|          | 7/2760 [03:51<23:34:52, 30.84s/ examples]Map:   0%|          | 8/2760 [04:11<21:07:36, 27.64s/ examples]Map:   0%|          | 9/2760 [04:18<16:01:59, 20.98s/ examples]Map:   0%|          | 10/2760 [04:46<17:44:03, 23.22s/ examples]Map:   0%|          | 11/2760 [08:19<62:04:34, 81.29s/ examples]Map:   0%|          | 12/2760 [08:50<50:22:54, 66.00s/ examples]Map:   0%|          | 13/2760 [09:09<39:33:22, 51.84s/ examples]Map:   1%|          | 14/2760 [09:38<34:11:04, 44.82s/ examples]Map:   1%|          | 15/2760 [10:07<30:33:28, 40.08s/ examples]Map:   1%|          | 16/2760 [11:54<46:00:44, 60.37s/ examples]Map:   1%|          | 17/2760 [12:07<35:06:23, 46.08s/ examples]slurmstepd-diamiktit: error: *** JOB 1055 ON diamiktit CANCELLED AT 2025-04-30T14:52:54 ***
