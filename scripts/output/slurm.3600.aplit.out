slurmstepd-aplit: error: Unable to create TMPDIR [/tmp/user/32202]: Permission denied
slurmstepd-aplit: error: Setting TMPDIR to /tmp
/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.
Loaded pretrained model EleutherAI/pythia-1.4b into HookedTransformer
Running compute_idiom_only on device cuda.

Processing split:  static
start: 0, end: 2761, len idiom_pos: 2761, len data: 2761
Traceback (most recent call last):
  File "/home/g/grimmj/IdiomHeads/compute_idiom_only.py", line 51, in <module>
    data = data.add_column("idiom_pos", scorer.idiom_positions)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 562, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/fingerprint.py", line 442, in wrapper
    out = func(dataset, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/arrow_dataset.py", line 5795, in add_column
    table = concat_tables([dataset._data, column_table], axis=1)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/table.py", line 1766, in concat_tables
    return ConcatenationTable.from_tables(tables, axis=axis)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/table.py", line 1471, in from_tables
    blocks = _extend_blocks(blocks, table_blocks, axis=axis)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/table.py", line 1463, in _extend_blocks
    result, blocks = _split_both_like(result, blocks)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/grimmj/miniconda3/envs/idiom/lib/python3.12/site-packages/datasets/table.py", line 1453, in _split_both_like
    raise ValueError("Failed to concatenate on axis=1 because tables don't have the same number of rows")
ValueError: Failed to concatenate on axis=1 because tables don't have the same number of rows
